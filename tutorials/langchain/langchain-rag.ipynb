{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we’ll use LangChain to walk through a step-by-step Retrieval Augmented Generation ([RAG](https://research.ibm.com/blog/retrieval-augmented-generation-RAG)) example in Python. For our use case, we’ll be setting up a RAG system for [IBM Think 2024](https://www.ibm.com/events/think). IBM Think 2024 is a conference or event where IBM announces new products, technologies, and partnerships.\n",
    "\n",
    "RAG is a technique in natural language processing (NLP) that combines information retrieval and generative models to produce more accurate, relevant and contextually aware responses. \n",
    "\n",
    "In traditional language generation tasks, [large language models](https://www.ibm.com/topics/large-language-models) (LLMs) like OpenAI’s GPT-3.5 (Generative Pre-trained Transformer) or [IBM’s Granite Models](https://www.ibm.com/products/watsonx-ai/foundation-models) are used to construct responses based on an input prompt. However, these models may struggle to produce responses that are contextually relevant, factually accurate or up to date. RAG applications address this limitation by incorporating a retrieval step before response generation. During retrieval, [vector search](https://www.ibm.com/topics/vector-search) can be used to identify contextually pertinent information, such as relevant information or documents from a large corpus of text, typically stored in a [vector database](https://www.ibm.com/topics/vector-database). Finally, an LLM is used to generate a response based on the retrieved context.\n",
    "\n",
    "LangChain is a powerful, open-source framework that facilitates the development of applications using LLMs for various NLP tasks. In the context of RAG, LangChain plays a critical role by combining the strengths of retrieval-based methods and generative models to enhance the capabilities of NLP systems.\n",
    "\n",
    "For this tutorial, we have downloaded content from a several IBM.com websites to create a knowledge base from where we will provide an LLM with context to answer some questions about Think 2024.\n",
    "\n",
    "The content and this Jupyter Notebook is available on [GitHub](https://github.com/Erika-Russi/think/tree/main/tutorials/langchain)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "You need an [IBM Cloud account](https://cloud.ibm.com/registration?utm_source=ibm_developer&utm_content=in_content_link&utm_id=tutorials_awb-implement-xgboost-in-python&cm_sp=ibmdev-_-developer-_-trial) to create a [watsonx.ai](https://www.ibm.com/products/watsonx-ai?utm_source=ibm_developer&utm_content=in_content_link&utm_id=tutorials_awb-implement-xgboost-in-python&cm_sp=ibmdev-_-developer-_-product) project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "## Step 1. Set up your environment\n",
    "\n",
    "While you can choose from several tools, this tutorial walks you through how to set up an IBM account to use a Jupyter Notebook. Jupyter Notebooks are widely used within [data science](https://www.ibm.com/topics/data-science) to combine code, text, images, and [data visualizations](https://www.ibm.com/topics/data-visualization) to formulate a well-formed analysis.\n",
    "\n",
    "1. Log in to [watsonx.ai](https://dataplatform.cloud.ibm.com/registration/stepone) using your IBM Cloud account.\n",
    "\n",
    "2. Create a [watsonx.ai project](https://www.ibm.com/docs/en/watsonx/saas?topic=projects-creating-project#create-a-project).\n",
    "\n",
    "3. Create a [Jupyter Notebook](https://www.ibm.com/docs/en/watsonx/saas?topic=editor-creating-notebooks).\n",
    "\n",
    "This step will open a Notebook environment where you can load your data set and copy the code from this tutorial to implement a binary classification task using the gradient boosting algorithm.\n",
    "\n",
    "## Step 2. Get an API Key for the IBM Generative AI Python SDK \n",
    "\n",
    "Create an IBMid and log in to https://bam.res.ibm.com/ to generate an API key. We have exported this credential as `GENAI_KEY` for this tutorial. The other credential we need to export is `GENAI_API`, which is `https://bam-api.res.ibm.com`.\n",
    "\n",
    "## Step 3. Install and import relevant libraries\n",
    "\n",
    "We'll need a few libraries for this tutorial. Make sure to import the ones below, and if they're not installed, you can resolve this with a quick pip install."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.1.16)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.32 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.0.34)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.1.50)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (0.1.46)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ibm-generative-ai in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (3.0.0)\n",
      "Requirement already satisfied: aiolimiter<2.0.0,>=1.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from ibm-generative-ai) (1.1.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from ibm-generative-ai) (2.7.1)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from ibm-generative-ai) (0.4.0)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from ibm-generative-ai) (0.27.0)\n",
      "Requirement already satisfied: deprecated<2.0.0,>=1.2.14 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from ibm-generative-ai) (1.2.14)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from deprecated<2.0.0,>=1.2.14->ibm-generative-ai) (1.16.0)\n",
      "Requirement already satisfied: anyio in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ibm-generative-ai) (4.4.0)\n",
      "Requirement already satisfied: idna in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ibm-generative-ai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ibm-generative-ai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ibm-generative-ai) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ibm-generative-ai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ibm-generative-ai) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->ibm-generative-ai) (4.11.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->ibm-generative-ai) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.0.0->ibm-generative-ai) (0.6.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ibm-generative-ai) (1.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_chroma in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain_chroma) (1.26.4)\n",
      "Requirement already satisfied: fastapi<1,>=0.95.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain_chroma) (0.111.0)\n",
      "Requirement already satisfied: chromadb<0.6.0,>=0.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain_chroma) (0.5.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.40 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain_chroma) (0.1.46)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.7.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (30.1.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.48.9)\n",
      "Requirement already satisfied: importlib-resources in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.4.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (6.0.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.66.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.18.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.5.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (8.2.3)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.1.3)\n",
      "Requirement already satisfied: requests>=2.28 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.31.0)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.64.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.7.1)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.2.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.10.1)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.30.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.11.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (7.7.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.12.3)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.0.4)\n",
      "Requirement already satisfied: python-multipart>=0.0.7 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.0.9)\n",
      "Requirement already satisfied: email_validator>=2.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (2.1.1)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.27.0)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (5.10.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (0.37.2)\n",
      "Requirement already satisfied: jinja2>=2.11.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from fastapi<1,>=0.95.2->langchain_chroma) (3.1.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (0.1.50)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from langchain-core<0.3,>=0.1.40->langchain_chroma) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from build>=1.0.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.0.1)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma) (2.6.1)\n",
      "Requirement already satisfied: idna>=2.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi<1,>=0.95.2->langchain_chroma) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.3.1)\n",
      "Requirement already satisfied: certifi in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.0.5)\n",
      "Requirement already satisfied: anyio in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (4.4.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2>=2.11.2->fastapi<1,>=0.95.2->langchain_chroma) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.40->langchain_chroma) (2.4)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.8.2)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.30.0)\n",
      "Requirement already satisfied: flatbuffers in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (24.3.25)\n",
      "Requirement already satisfied: sympy in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.12.1)\n",
      "Requirement already satisfied: protobuf in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.25.3)\n",
      "Requirement already satisfied: coloredlogs in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (15.0.1)\n",
      "Requirement already satisfied: importlib-metadata<=7.1,>=6.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (7.1.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.25.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.25.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.63.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.46b0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.46b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (65.5.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.16.0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.2.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pydantic>=1.9->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.18.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests>=2.28->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.23.3)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (13.7.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.5.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (8.1.7)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (12.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.22.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi<1,>=0.95.2->langchain_chroma) (1.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (5.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2024.6.0)\n",
      "Requirement already satisfied: filelock in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.18.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (2.16.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (3.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb<0.6.0,>=0.4.0->langchain_chroma) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.6.0,>=0.4.0->langchain_chroma) (0.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: lxml in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (5.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (3.0.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.66.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (4.41.2)\n",
      "Requirement already satisfied: scipy in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (0.23.3)\n",
      "Requirement already satisfied: Pillow in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: numpy in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: requests in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.0)\n",
      "Requirement already satisfied: jinja2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: networkx in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: sympy in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12.1)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.4.16)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#installations\n",
    "%pip install langchain\n",
    "%pip install ibm-generative-ai\n",
    "%pip install langchain_chroma\n",
    "%pip install beautifulsoup4\n",
    "%pip install lxml\n",
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "from langchain_community.document_loaders import (\n",
    "    BSHTMLLoader, \n",
    "    TextLoader,\n",
    ")\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "from genai import Credentials, Client\n",
    "from genai.extensions.langchain.chat_llm import LangChainChatInterface\n",
    "from genai.schema import (\n",
    "    TextGenerationParameters,\n",
    "    TextGenerationReturnOptions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure that `GENAI_KEY` and `GENAI_API` variables are exported correctly. The below code should return `True` when the variables have been loaded from a `.env` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 4. Indexing\n",
    "\n",
    "We’ll index our Think 2024 specific articles to create a knowledge base as a vectorstore. The first step to building vector embeddings is to clean and process the raw dataset. This may involve the removal of noise and standardization of the text. For our example, we won’t do any cleaning since the text is already cleaned and standardized.\n",
    "\n",
    "First, let's set up a a helper function to help us load the URLs we have in `URLS_DICTIONARY`. `URLS_DICTIONARY` helps us map the file names to the URL from which we extracted the content. Let's also establish a name for our collection: `askibm_think_2024`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./corpus/ibm.com_events_think_faq.html': 'https://www.ibm.com/events/think/faq',\n",
       " './corpus/events_think_agenda.html': 'https://www.ibm.com/events/think/agenda',\n",
       " './corpus/products_watsonx_ai.html': 'https://www.ibm.com/products/watsonx-ai',\n",
       " './corpus/products_watsonx_ai_foundation_models.html': 'https://www.ibm.com/products/watsonx-ai/foundation-models',\n",
       " './corpus/watsonx_pricing.html': 'https://www.ibm.com/watsonx/pricing',\n",
       " './corpus/watsonx.html': 'https://www.ibm.com/watsonx',\n",
       " './corpus/products_watsonx_data.html': 'https://www.ibm.com/products/watsonx-data',\n",
       " './corpus/products_watsonx_assistant.html': 'https://www.ibm.com/products/watsonx-assistant',\n",
       " './corpus/products_watsonx_code_assistant.html': 'https://www.ibm.com/products/watsonx-code-assistant',\n",
       " './corpus/products_watsonx_orchestrate.html': 'https://www.ibm.com/products/watsonx-orchestrate',\n",
       " './corpus/products_watsonx_governance.html': 'https://www.ibm.com/products/watsonx-governance',\n",
       " './corpus/granite_code_models_open_source.html': 'https://research.ibm.com/blog/granite-code-models-open-source',\n",
       " './corpus/red_hat_enterprise_linux_ai.html': 'https://www.redhat.com/en/about/press-releases/red-hat-delivers-accessible-open-source-generative-ai-innovation-red-hat-enterprise-linux-ai',\n",
       " './corpus/model_choice.html': 'https://www.ibm.com/blog/announcement/enterprise-grade-model-choices/',\n",
       " './corpus/democratizing.html': 'https://www.ibm.com/blog/announcement/democratizing-large-language-model-development-with-instructlab-support-in-watsonx-ai/',\n",
       " './corpus/ibm_consulting_expands_ai.html': 'https://newsroom.ibm.com/Blog-IBM-Consulting-Expands-Capabilities-to-Help-Enterprises-Scale-AI',\n",
       " './corpus/ibm_data_product_hub.html': 'https://www.ibm.com/products/data-product-hub',\n",
       " './corpus/ibm_price_performance_data.html': 'https://www.ibm.com/blog/announcement/delivering-superior-price-performance-and-enhanced-data-management-for-ai-with-ibm-watsonx-data/',\n",
       " './corpus/ibm_bi_adoption.html': 'https://www.ibm.com/blog/a-new-era-in-bi-overcoming-low-adoption-to-make-smart-decisions-accessible-for-all/',\n",
       " './corpus/watsonx_code_assistant_for_z.html': 'https://www.ibm.com/blog/announcement/ibm-watsonx-code-assistant-for-z-accelerate-the-application-lifecycle-with-generative-ai-and-automation/',\n",
       " './corpus/code_assistant_for_java.html': 'https://www.ibm.com/blog/announcement/watsonx-code-assistant-java/',\n",
       " './corpus/code_assistant_for_orchestrate.html': 'https://www.ibm.com/blog/announcement/watsonx-orchestrate-ai-z-assistant/',\n",
       " './corpus/accelerating_gen_ai.html': 'https://newsroom.ibm.com/Blog-How-IBM-Cloud-is-Accelerating-Business-Outcomes-with-Gen-AI',\n",
       " './corpus/watsonx_open_source.html': 'https://newsroom.ibm.com/2024-05-21-IBM-Unveils-Next-Chapter-of-watsonx-with-Open-Source,-Product-Ecosystem-Innovations-to-Drive-Enterprise-AI-at-Scale',\n",
       " './corpus/announcements.txt': 'Think 2024 Announcements',\n",
       " './corpus/ibm_concert.txt': 'IBM Concert',\n",
       " './corpus/ibm_consulting_advantage_news.html': 'https://newsroom.ibm.com/2024-01-17-IBM-Introduces-IBM-Consulting-Advantage,-an-AI-Services-Platform-and-Library-of-Assistants-to-Empower-Consultants',\n",
       " './corpus/ibm_consulting_advantage_info.html': 'https://www.ibm.com/consulting/info/ibm-consulting-advantage'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_urls(json_file: str) -> dict[str, str]:\n",
    "    with open(json_file, \"r\") as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "URLS_DICTIONARY = load_urls(\"./sources/sources.json\")\n",
    "COLLECTION_NAME = \"askibm_think_2024\"\n",
    "URLS_DICTIONARY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up a function `load_think_corpus()` to help us load the files from our data sources. And we'll load the files in the [`corpus` directory](https://github.com/Erika-Russi/think/tree/main/tutorials/langchain/corpus) so they're ready to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_think_corpus(directory, text=False):\n",
    "\n",
    "    html_files = glob.glob(directory + \"/\" + \"*.html\")\n",
    "\n",
    "    if text:\n",
    "        html_files = glob.glob(directory + \"/\" + \"*.txt\")\n",
    "\n",
    "    return html_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./corpus/ibm_concert.txt', './corpus/announcements.txt']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./corpus/products_watsonx_ai_foundation_models.html',\n",
       " './corpus/products_watsonx_data.html',\n",
       " './corpus/products_watsonx_governance.html',\n",
       " './corpus/ibm.com_events_think_faq.html',\n",
       " './corpus/ibm_price_performance_data.html',\n",
       " './corpus/accelerating_gen_ai.html',\n",
       " './corpus/code_assistant_for_orchestrate.html',\n",
       " './corpus/red_hat_enterprise_linux_ai.html',\n",
       " './corpus/watsonx_open_source.html',\n",
       " './corpus/granite_code_models_open_source.html',\n",
       " './corpus/watsonx.html',\n",
       " './corpus/products_watsonx_code_assistant.html',\n",
       " './corpus/ibm_consulting_advantage_info.html',\n",
       " './corpus/events_think_agenda.html',\n",
       " './corpus/products_watsonx_assistant.html',\n",
       " './corpus/products_watsonx_orchestrate.html',\n",
       " './corpus/ibm_consulting_advantage_news.html',\n",
       " './corpus/democratizing.html',\n",
       " './corpus/products_watsonx_ai.html',\n",
       " './corpus/watsonx_pricing.html',\n",
       " './corpus/ibm_data_product_hub.html',\n",
       " './corpus/ibm_consulting_expands_ai.html',\n",
       " './corpus/watsonx_code_assistant_for_z.html',\n",
       " './corpus/code_assistant_for_java.html',\n",
       " './corpus/model_choice.html',\n",
       " './corpus/ibm_bi_adoption.html']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_corpus_files = load_think_corpus(\"./corpus\")\n",
    "text_corpus_files = load_think_corpus(\"./corpus\", text=True)\n",
    "print(text_corpus_files)\n",
    "html_corpus_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our documents using the LangChain BSHTMLLoader for our HTML files and the TextLoader for our txt files. We'll print a sample document at the end to see how it's been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"\\n\\n\\n\\n\\n\\n\\nFoundation Models - IBM watsonx.ai\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFoundation models in watsonx.ai\\xa0\\n\\n\\n\\n                        \\n\\n\\n  \\n  \\n      Explore the IBM library of foundation models on the watsonx platform to scale generative AI for your business with confidence \\n  \\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\nStart your free trial \\n\\n\\nBook a live demo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    Enterprise-grade models with the power of choice \\n\\n\\n\\n\\n\\n    \\n\\n\\n            \\n        \\n\\n\\n\\n\\nIBM watsonx™ models\\xa0are designed for the enterprise and optimized for targeted business domains and use cases. Through the AI studio IBM®\\xa0watsonx.ai™ we\\xa0offer a selection of cost-effective, enterprise-grade foundation models developed by IBM, open-source models and models sourced from third-party providers to help clients and partners scale and operationalize\\xa0artificial intelligence (AI) faster with minimal risk. You can deploy the AI models\\xa0wherever your workload is,\\xa0both on-premises and on hybrid cloud.\\nIBM takes a differentiated approach to delivering enterprise-grade foundation models:\\nOpen: Bring best-in-class IBM and proven open-source models to watsonx foundation model library or your library.Trusted:\\xa0Train models on trusted and governed data for applications that require enterprise-level transparency, governance and performance.Targeted:\\xa0Designed for the enterprise and optimized for targeted business domains and use cases.Empowering:\\xa0Empower clients with competitively priced model choices to build AI that best suits their unique business needs and risk profiles.\\n\\n\\n\\nEbook: Explore how to choose the right foundation model \\n                \\n            \\n\\n\\n\\n\\n\\n\\n                What's new\\n            \\n\\n                Llama 3 is now available in watsonx foundation model library.\\n            \\n\\nSee the details \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    IBM models\\n\\n\\n\\n\\n\\n    \\n\\n\\n            \\n        \\n\\n\\n\\n\\nIBM watsonx foundation models\\xa0library\\xa0gives you the choice\\xa0and flexibility to choose the model that best fits your business needs, regional interests and risk profiles\\xa0from a library of proprietary, open-source and third-party models.\\n\\n\\n\\n\\n\\n\\n      \\n\\n\\n\\n  \\n    Granite, developed by IBM Research\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nGranite is IBM's flagship series of LLM foundation models based on decoder-only transformer architecture. Granite language models are trained on trusted enterprise data spanning internet, academic, code, legal and finance. Currently we have four models in the Granite series.\\nGranite 13b chat: Chat model optimized for dialogue use cases and works well with virtual agent and chat applicationsGranite 13b instruct: Instruct model trained on high-quality finance data to perform well in finance domain tasksGranite multilingual: Trained to understand and generate text in English, German, Spanish, French and PortugueseGranite Japanese: Designed to perform language tasks on Japanese text\\n\\n\\n\\n\\n\\n      \\n\\n\\n\\n  \\n    IBM Embedding Models\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nUse IBM developed and open-sourced embedding models, deployed in IBM watsonx.ai, for retrieval augmented generation, semantic search and document comparison tasks.\\nslate-125m-english-rtrvr: provided by IBM with an output dimension of 768slate-30m-english-rtrvr: provided by IBM with an output dimension of 384\\n\\n\\n\\n\\n\\n\\n\\nTry watsonx.ai for free\\n\\n\\n\\n\\n\\n IBM Research report\\n\\n\\nSee how Granite models were trained and data sources used\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    Why IBM Granite?\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n                \\n                \\n\\n\\n  \\n  \\n       \\xa0 \\xa0 \\xa0 \\xa0\\n  \\n\\n\\n\\n\\n    \\n\\n\\n                \\n            \\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Trusted\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nTrained on enterprise relevant content,\\xa0IBM Granite meets rigorous data governance, regulatory and risk criteria defined and enforced by the IBM AI Ethics code and Chief Privacy Office.\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Performant \\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nImproved accuracy for targeted enterprise business domains such as finance and use cases like RAG, achieved through chat fine-tuning and model alignment techniques.\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Cost-effective\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nA competitively priced model with less infrastructure requirement, IP indemnification and an easy-to-use toolkit for model customization and application integration.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    Foundation model library\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n            \\n\\n\\n\\n\\nSelect a generative foundation model that best fits your needs.\\xa0After you have a short list of models for your use case, systematically test the models by using prompt engineering techniques to see which ones consistently return the desired results.\\n\\n\\n\\n\\nSee more watsonx pricing information \\n                \\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n  \\n  \\n      Model name\\n  \\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n                \\n\\n\\n  \\n  \\n      Provider\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n                \\n\\n\\n  \\n  \\n      Use cases\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n                \\n\\n\\n  \\n  \\n      Context length\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n                \\n\\n\\n  \\n  \\n      Price \\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n                \\n\\n\\n  \\n  \\n      USD/1 million tokens\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n\\n\\n\\n\\ngranite-7b-lab\\n\\n\\n New\\n\\n\\n\\n\\n\\nIBM\\n\\n\\n\\n\\nSupports questions and answers (Q&A), summarization, classification, generation, extraction and RAG tasks.\\xa0\\n\\xa0\\n\\n\\n\\n\\n8128\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\ngranite-13b-chat\\xa0\\n\\n\\n Featured model\\n\\n\\n\\n\\n\\nIBM\\n\\n\\n\\n\\nSupports questions and answers (Q&A), summarization, classification, generation, extraction and RAG tasks.\\xa0\\n\\xa0\\n\\n\\n\\n\\n8192\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\ngranite-13b-instruct\\n\\n\\n Featured model\\n\\n\\n\\n\\n\\nIBM\\xa0\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks.\\n\\n\\n\\n\\n8192\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\ngranite-20b-multilingual\\n\\n\\n Featured model\\n\\n\\n\\n\\n\\nIBM\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction, translation and RAG tasks in French, German, Portuguese, Spanish and English.\\n\\n\\n\\n\\n\\n8190\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\ngranite-8b-japanese\\n\\n\\n New\\n\\n\\n\\n\\n\\nIBM\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction, translation and RAG tasks in Japanese.\\xa0\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\nllama-3-8b-instruct\\n\\n\\n New\\n\\n\\n\\n\\n\\nMeta\\n\\n\\n\\n\\nSupports summarization, classification, generation, extraction and translation\\xa0 tasks.\\n\\n\\n\\n\\n8192\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\nllama-3-70b-instruct\\n\\n\\n New\\n\\n\\n\\n\\n\\nMeta\\n\\n\\n\\n\\nSupports RAG, generation, summarization, classification, Q&A, extraction, translation and code generation tasks.\\n\\n\\n\\n\\n8192\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nllama-2-70b-chat\\n\\n\\n\\n\\nMeta\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks.\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nllama-2-13b-chat\\n\\n\\n\\n\\nMeta\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks. Available for prompt tuning.\\xa0\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\nllama2-13b-dpo-v7 (Korean)\\n\\n\\n New\\n\\n\\n\\n\\n\\nMindsAndCompany\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks in Korean.\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\ncodellama-34b-instruct\\n\\n\\n New\\n\\n\\n\\n\\n\\nMeta\\n\\n\\n\\n\\nTask-specific model for code by generating and translating code from a natural language prompt.\\n\\n\\n\\n\\n16384\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nmixtral-8x7b-instruct\\n\\n\\n New\\n\\n\\n\\n\\n\\nMistral AI\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction, RAG and code generation tasks.\\n\\n\\n\\n\\n32768\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\nmerlinite-7b\\n\\n\\n New\\n\\n\\n\\n\\n\\nibm-mistralai\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction, RAG and code generation tasks.\\n\\n\\n\\n\\n32768\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\njais-13b-chat (Arabic)\\n\\n\\n New\\n\\n\\n\\n\\n\\ncore42\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and translation in Arabic.\\n\\n\\n\\n\\n2048\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nflan-t5-xl-3b\\n\\n\\n\\n\\nGoogle\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks. Available for prompt-tuning.\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n0.60\\n\\n\\n\\n\\n\\n\\nflan-t5-xxl-11b\\n\\n\\n\\n\\nGoogle\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks.\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nflan-ul2-20b\\n\\n\\n\\n\\nGoogle\\n\\n\\n\\n\\nSupports Q&A, summarization, classification, generation, extraction and RAG tasks.\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n5.00\\n\\n\\n\\n\\n\\n\\nelyza-japanese-llama-2-7b-instruct\\n\\n\\n\\n\\nELYZA\\n\\n\\n\\n\\nSupports Q&A, summarization, RAG, classification, generation, extraction and translation tasks.\\xa0\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nmt0-xxl-13b\\n\\n\\n\\n\\nBigScience\\xa0\\n\\n\\n\\n\\nSupports Q&A, summarization, classification and generation tasks.\\n\\n\\n\\n\\n4096\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\nstarcoder-15.5b\\n\\n\\n\\n\\nBigCode\\n\\n\\n\\n\\nTask-specific model for code by generating and translating code from a natural language prompt.\\n\\n\\n\\n\\n8192\\n\\n\\n\\n\\n1.80\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    Embedding model library\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n            \\n\\n\\n\\n\\nEmbedding models convert input text into embeddings, which are dense vector representations of the input text. Embeddings capture nuanced semantic and syntactic relationships between words and passages in vector space.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n  \\n  \\n      Model name\\n  \\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n                \\n\\n\\n  \\n  \\n      Provider\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n                \\n\\n\\n  \\n  \\n      Use cases\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n                \\n\\n\\n  \\n  \\n      Context length\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n                \\n\\n\\n  \\n  \\n      Price \\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n                \\n\\n\\n  \\n  \\n      USD/1 million tokens\\n  \\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n\\n\\n\\n\\nslate-125m-english-rtrvr\\n\\n\\n New\\n\\n\\n\\n\\n\\nIBM\\n\\n\\n\\n\\nRetrieval augmented generation, semantic search and document comparison tasks.\\n\\xa0\\n\\n\\n\\n\\n512\\n\\n\\n\\n\\n0.10\\n\\n\\n\\n\\n\\n\\nslate-30m-english-rtrvr\\n\\n\\n New\\n\\n\\n\\n\\n\\nIBM\\n\\n\\n\\n\\nRetrieval augmented generation, semantic search and document comparison tasks.\\n\\xa0\\n\\n\\n\\n\\n512\\n\\n\\n\\n\\n0.10\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    Client stories\\n\\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n\\nBusinesses are excited about the prospect of tapping foundation models and ML in one place, with their own data, to accelerate generative AI workloads.\\xa0\\n\\n\\n\\n\\n\\n\\n\\nExplore more client stories\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWimbledon \\nWimbledon used watsonx.ai foundation models to train its AI to create tennis commentary.\\n\\n                    \\n                        Read the case study \\n                    \\n                    \\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            The Recording Academy®\\n        \\n\\n            The Recording Academy® used AI Stories with IBM watsonx to generate and scale editorial content around GRAMMY® nominees.\\n        \\n\\nRead the announcement \\n\\n\\n\\n\\n\\n\\n\\n\\n            The Masters\\n        \\n\\n            Watsonx brings AI-powered hole insights and Spanish language AI narration to the Masters Tournament digital platforms.\\n        \\n\\nRead the announcement \\n\\n\\n\\n\\n\\n\\n\\n\\n            AddAI.Life\\n        \\n\\n            AddAI.Life uses watsonx.ai to access selected open-source large language models to build higher quality virtual assistants.\\n        \\n\\nRead the case study \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    News and resources\\n\\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n\\n\\n            News\\n        \\n\\n            Open-source Mixtral 8x7b model now available on watsonx to help enterprises scale AI with trust and flexibility \\n        \\n\\nRead the announcement \\n\\n\\n\\n\\n\\n\\n            Ebook \\n        \\n\\n            How to choose the right AI foundation model \\n        \\n\\nRead the ebook \\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            Generative AI and ML for the enterprise\\n        \\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n            News\\n        \\n\\n            IBM and Meta Llama 2 launches in watsonx.ai, improving AI productivity\\n        \\n\\nRead the announcement \\n\\n\\n\\n\\n\\n\\n            Blog\\n        \\n\\n            Hugging Face and IBM working together in open source\\n        \\n\\nRead the blog\\n\\n\\n\\n\\n\\n\\n            Blog\\n        \\n\\n            Building AI for business: IBM Granite foundation models\\n        \\n\\nRead the blog \\n\\n\\n\\n\\n\\n\\n            Blog\\n        \\n\\n            Introducing the technology behind watsonx.ai\\n        \\n\\nRead the blog \\n\\n\\n\\n\\n\\n\\n            White paper\\n        \\n\\n            Presto: Make sense of all your data\\n        \\n\\nRead the white paper\\n\\n\\n\\n\\n\\n\\n            Blog\\n        \\n\\n            How IBM is tailoring generative AI for enterprises\\n        \\n\\nRead the blog\\n\\n\\n\\n\\n\\n\\n            Blog\\n        \\n\\n            Learn more about the power of AI tailored to your unique needs\\n        \\n\\nRead the blog \\n\\n\\n\\n\\n\\n\\n            Video \\n        \\n\\n            See how to build enterprise-ready foundation models\\n        \\n\\nWatch the video \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\n\\n\\n    Intellectual property protection for AI models\\n\\n\\n\\n\\n\\n    \\n\\n\\n            \\n\\n\\n\\n\\n\\nIBM believes in the creation, deployment and utilization of AI models that advance innovation across the enterprise responsibly. IBM watsonx AI and data platform has an end-to-end process for building and testing foundation models and generative AI. For IBM-developed models, we search for and remove duplication, and we employ URL blocklists, filters for objectionable content and document quality, sentence splitting and tokenization techniques, all before model training.\\n\\nDuring the data training process, we work to prevent misalignments in the model outputs and use supervised fine-tuning to enable better instruction following so that the model can be used to complete enterprise tasks via prompt engineering. We are continuing to develop the Granite models in several directions, including other modalities, industry-specific content and more data annotations for training, while also deploying regular, ongoing data protection safeguards for IBM developed-models. \\xa0\\nGiven the rapidly changing generative AI technology landscape, our end-to-end processes is expected to continuously evolve and improve.\\xa0As a testament to the rigor IBM puts into the development and testing of its foundation models, the company provides its standard contractual intellectual property indemnification for IBM-developed models, similar to those it provides for IBM hardware and software products.\\n\\nMoreover, contrary to some other providers of large language models and consistent with the IBM standard approach on indemnification, IBM does not require its customers to indemnify IBM for a customer's use of IBM-developed models. Also, consistent with the IBM approach to its indemnification obligation, IBM does not cap its indemnification liability for the IBM-developed models.\\nThe current watsonx models now under these protections include:\\n(1) Slate family of encoder-only models.\\n(2) Granite family of a decoder-only model.\\nLearn more about licensing for Granite models\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nTake the next step to start operationalizing and scaling generative AI and machine learning for business.\\n\\n\\n\\n\\n\\n\\nStart your free trial\\n\\n\\nBook a live demo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n  \\n  \\n      More ways to explore\\n  \\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n                                Become an IBM Business Partner\\n                                \\n                                \\n        \\n\\n                                Connect with the IBM Community\\n                                \\n                                \\n        \\n\\n                                SaaS documentation\\n                                \\n                                \\n        \\n\\n                                Software documentation \\n                                \\n                                \\n        \\n\\n                                Support\\n                                \\n                                \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            \\n\\n\\n\\n  \\n    Footnotes\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                        \\n\\n\\n\\n\\n\\nInference is billed in Resource Units. 1 Resource Unit is 1,000 tokens. Input and completion tokens are charged at the same rate. 1,000 tokens are generally about 750 words.\\n\\nNot all models are available in all regions,\\xa0see our documentation for details.\\nContext length is expressed in tokens.\\nThe IBM statements regarding its plans, directions and intent are subject to change or withdrawal without notice at its sole discretion. See\\xa0Pricing\\xa0for more details. Unless otherwise specified under Software pricing, all features, capabilities and potential updates refer exclusively to SaaS. IBM makes no representation that SaaS and software features and capabilities are the same.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': './corpus/products_watsonx_ai_foundation_models.html', 'title': 'Foundation Models - IBM watsonx.ai'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = []\n",
    "\n",
    "\n",
    "for f in html_corpus_files:\n",
    "    loader = BSHTMLLoader(f)\n",
    "    data = loader.load()\n",
    "    documents += data\n",
    "\n",
    "for f in text_corpus_files:\n",
    "    loader = TextLoader(f)\n",
    "    documents += loader.load()\n",
    "\n",
    "#show sample document\n",
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the sample document, it looks like there's a lot of white space and new line characters that we can get rid of. Let's clean that up and add some metadata to our documents, including an id number and the source of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': './corpus/products_watsonx_ai_foundation_models.html', 'title': 'Foundation Models - IBM watsonx.ai', 'id': 0, 'fileName': 'https://www.ibm.com/products/watsonx-ai/foundation-models'}\n",
      "{'source': './corpus/products_watsonx_data.html', 'title': 'IBM watsonx.data', 'id': 1, 'fileName': 'https://www.ibm.com/products/watsonx-data'}\n",
      "{'source': './corpus/products_watsonx_governance.html', 'title': 'IBM watsonx.governance', 'id': 2, 'fileName': 'https://www.ibm.com/products/watsonx-governance'}\n",
      "{'source': './corpus/ibm.com_events_think_faq.html', 'title': 'Think 2024 FAQ | IBM', 'id': 3, 'fileName': 'https://www.ibm.com/events/think/faq'}\n",
      "{'source': './corpus/ibm_price_performance_data.html', 'title': 'Delivering superior price-performance and enhanced data management for AI with IBM watsonx.data - IBM Blog', 'id': 4, 'fileName': 'https://www.ibm.com/blog/announcement/delivering-superior-price-performance-and-enhanced-data-management-for-ai-with-ibm-watsonx-data/'}\n",
      "{'source': './corpus/accelerating_gen_ai.html', 'title': 'How IBM Cloud is Accelerating Business Outcomes with Gen AI', 'id': 5, 'fileName': 'https://newsroom.ibm.com/Blog-How-IBM-Cloud-is-Accelerating-Business-Outcomes-with-Gen-AI'}\n",
      "{'source': './corpus/code_assistant_for_orchestrate.html', 'title': 'Announcing IBM watsonx Assistant for Z and D&B Ask Procurement, new generative AI assistants built with IBM watsonx Orchestrate - IBM Blog', 'id': 6, 'fileName': 'https://www.ibm.com/blog/announcement/watsonx-orchestrate-ai-z-assistant/'}\n",
      "{'source': './corpus/red_hat_enterprise_linux_ai.html', 'title': 'Red Hat Delivers Accessible, Open Source Generative AI Innovation with Red Hat Enterprise Linux AI', 'id': 7, 'fileName': 'https://www.redhat.com/en/about/press-releases/red-hat-delivers-accessible-open-source-generative-ai-innovation-red-hat-enterprise-linux-ai'}\n",
      "{'source': './corpus/watsonx_open_source.html', 'title': 'IBM Unveils Next Chapter of watsonx with Open Source, Product & Ecosystem Innovations to Drive Enterprise AI at Scale', 'id': 8, 'fileName': 'https://newsroom.ibm.com/2024-05-21-IBM-Unveils-Next-Chapter-of-watsonx-with-Open-Source,-Product-Ecosystem-Innovations-to-Drive-Enterprise-AI-at-Scale'}\n",
      "{'source': './corpus/granite_code_models_open_source.html', 'title': 'IBM’s Granite code model family is going open source - IBM Research', 'id': 9, 'fileName': 'https://research.ibm.com/blog/granite-code-models-open-source'}\n",
      "{'source': './corpus/watsonx.html', 'title': 'IBM watsonx —\\xa0An AI and data platform built for business ', 'id': 10, 'fileName': 'https://www.ibm.com/watsonx'}\n",
      "{'source': './corpus/products_watsonx_code_assistant.html', 'title': 'IBM watsonx Code Assistant ', 'id': 11, 'fileName': 'https://www.ibm.com/products/watsonx-code-assistant'}\n",
      "{'source': './corpus/ibm_consulting_advantage_info.html', 'title': 'IBM Consulting Advantage', 'id': 12, 'fileName': 'https://www.ibm.com/consulting/info/ibm-consulting-advantage'}\n",
      "{'source': './corpus/events_think_agenda.html', 'title': 'IBM Think 2024 Agenda', 'id': 13, 'fileName': 'https://www.ibm.com/events/think/agenda'}\n",
      "{'source': './corpus/products_watsonx_assistant.html', 'title': 'IBM watsonx Assistant Virtual Agent', 'id': 14, 'fileName': 'https://www.ibm.com/products/watsonx-assistant'}\n",
      "{'source': './corpus/products_watsonx_orchestrate.html', 'title': 'IBM watsonx Orchestrate', 'id': 15, 'fileName': 'https://www.ibm.com/products/watsonx-orchestrate'}\n",
      "{'source': './corpus/ibm_consulting_advantage_news.html', 'title': 'IBM Introduces IBM Consulting Advantage, an AI Services Platform and Library of Assistants to Empower Consultants - Jan 17, 2024', 'id': 16, 'fileName': 'https://newsroom.ibm.com/2024-01-17-IBM-Introduces-IBM-Consulting-Advantage,-an-AI-Services-Platform-and-Library-of-Assistants-to-Empower-Consultants'}\n",
      "{'source': './corpus/democratizing.html', 'title': 'Democratizing Large Language Model development with InstructLab support in watsonx.ai - IBM Blog', 'id': 17, 'fileName': 'https://www.ibm.com/blog/announcement/democratizing-large-language-model-development-with-instructlab-support-in-watsonx-ai/'}\n",
      "{'source': './corpus/products_watsonx_ai.html', 'title': 'IBM watsonx.ai ', 'id': 18, 'fileName': 'https://www.ibm.com/products/watsonx-ai'}\n",
      "{'source': './corpus/watsonx_pricing.html', 'title': 'IBM watsonx | Pricing', 'id': 19, 'fileName': 'https://www.ibm.com/watsonx/pricing'}\n",
      "{'source': './corpus/ibm_data_product_hub.html', 'title': 'IBM Data Product Hub', 'id': 20, 'fileName': 'https://www.ibm.com/products/data-product-hub'}\n",
      "{'source': './corpus/ibm_consulting_expands_ai.html', 'title': 'IBM Consulting Expands Capabilities to Help Enterprises Scale AI', 'id': 21, 'fileName': 'https://newsroom.ibm.com/Blog-IBM-Consulting-Expands-Capabilities-to-Help-Enterprises-Scale-AI'}\n",
      "{'source': './corpus/watsonx_code_assistant_for_z.html', 'title': 'IBM watsonx Code Assistant for Z: accelerate the application lifecycle with generative AI and automation - IBM Blog', 'id': 22, 'fileName': 'https://www.ibm.com/blog/announcement/ibm-watsonx-code-assistant-for-z-accelerate-the-application-lifecycle-with-generative-ai-and-automation/'}\n",
      "{'source': './corpus/code_assistant_for_java.html', 'title': 'Accelerating the Java application lifecycle with generative AI and automation - IBM Blog', 'id': 23, 'fileName': 'https://www.ibm.com/blog/announcement/watsonx-code-assistant-java/'}\n",
      "{'source': './corpus/model_choice.html', 'title': 'New strategic partnerships from IBM offer clients a wide range of enterprise-grade model choices - IBM Blog', 'id': 24, 'fileName': 'https://www.ibm.com/blog/announcement/enterprise-grade-model-choices/'}\n",
      "{'source': './corpus/ibm_bi_adoption.html', 'title': 'A new era in BI: Overcoming low adoption to make smart decisions accessible for all - IBM Blog', 'id': 25, 'fileName': 'https://www.ibm.com/blog/a-new-era-in-bi-overcoming-low-adoption-to-make-smart-decisions-accessible-for-all/'}\n",
      "{'source': './corpus/ibm_concert.txt', 'id': 26, 'fileName': 'IBM Concert', 'title': 'IBM Concert'}\n",
      "{'source': './corpus/announcements.txt', 'id': 27, 'fileName': 'Think 2024 Announcements', 'title': 'Think 2024 Announcements'}\n"
     ]
    }
   ],
   "source": [
    "doc_id = 0\n",
    "for doc in documents:\n",
    "    doc.page_content = \" \".join(doc.page_content.split()) # remove white space\n",
    "\n",
    "    \n",
    "    doc.metadata[\"id\"] = doc_id #make a document id and add it to the document metadata\n",
    "    doc.metadata[\"fileName\"] = URLS_DICTIONARY[doc.metadata[\"source\"]]\n",
    "\n",
    "    if \"title\" not in doc.metadata.keys():\n",
    "        doc.metadata[\"title\"] = URLS_DICTIONARY[doc.metadata[\"source\"]].replace(\".txt\", \"\")\n",
    "\n",
    "    print(doc.metadata)\n",
    "    doc_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our sample document looks now after we cleaned it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Foundation Models - IBM watsonx.ai Foundation models in watsonx.ai Explore the IBM library of foundation models on the watsonx platform to scale generative AI for your business with confidence Start your free trial Book a live demo Enterprise-grade models with the power of choice IBM watsonx™ models are designed for the enterprise and optimized for targeted business domains and use cases. Through the AI studio IBM® watsonx.ai™ we offer a selection of cost-effective, enterprise-grade foundation models developed by IBM, open-source models and models sourced from third-party providers to help clients and partners scale and operationalize artificial intelligence (AI) faster with minimal risk. You can deploy the AI models wherever your workload is, both on-premises and on hybrid cloud. IBM takes a differentiated approach to delivering enterprise-grade foundation models: Open: Bring best-in-class IBM and proven open-source models to watsonx foundation model library or your library.Trusted: Train models on trusted and governed data for applications that require enterprise-level transparency, governance and performance.Targeted: Designed for the enterprise and optimized for targeted business domains and use cases.Empowering: Empower clients with competitively priced model choices to build AI that best suits their unique business needs and risk profiles. Ebook: Explore how to choose the right foundation model What's new Llama 3 is now available in watsonx foundation model library. See the details IBM models IBM watsonx foundation models library gives you the choice and flexibility to choose the model that best fits your business needs, regional interests and risk profiles from a library of proprietary, open-source and third-party models. Granite, developed by IBM Research Granite is IBM's flagship series of LLM foundation models based on decoder-only transformer architecture. Granite language models are trained on trusted enterprise data spanning internet, academic, code, legal and finance. Currently we have four models in the Granite series. Granite 13b chat: Chat model optimized for dialogue use cases and works well with virtual agent and chat applicationsGranite 13b instruct: Instruct model trained on high-quality finance data to perform well in finance domain tasksGranite multilingual: Trained to understand and generate text in English, German, Spanish, French and PortugueseGranite Japanese: Designed to perform language tasks on Japanese text IBM Embedding Models Use IBM developed and open-sourced embedding models, deployed in IBM watsonx.ai, for retrieval augmented generation, semantic search and document comparison tasks. slate-125m-english-rtrvr: provided by IBM with an output dimension of 768slate-30m-english-rtrvr: provided by IBM with an output dimension of 384 Try watsonx.ai for free IBM Research report See how Granite models were trained and data sources used Why IBM Granite? Trusted Trained on enterprise relevant content, IBM Granite meets rigorous data governance, regulatory and risk criteria defined and enforced by the IBM AI Ethics code and Chief Privacy Office. Performant Improved accuracy for targeted enterprise business domains such as finance and use cases like RAG, achieved through chat fine-tuning and model alignment techniques. Cost-effective A competitively priced model with less infrastructure requirement, IP indemnification and an easy-to-use toolkit for model customization and application integration. Foundation model library Select a generative foundation model that best fits your needs. After you have a short list of models for your use case, systematically test the models by using prompt engineering techniques to see which ones consistently return the desired results. See more watsonx pricing information Model name Provider Use cases Context length Price USD/1 million tokens granite-7b-lab New IBM Supports questions and answers (Q&A), summarization, classification, generation, extraction and RAG tasks. 8128 0.60 granite-13b-chat Featured model IBM Supports questions and answers (Q&A), summarization, classification, generation, extraction and RAG tasks. 8192 0.60 granite-13b-instruct Featured model IBM Supports Q&A, summarization, classification, generation, extraction and RAG tasks. 8192 0.60 granite-20b-multilingual Featured model IBM Supports Q&A, summarization, classification, generation, extraction, translation and RAG tasks in French, German, Portuguese, Spanish and English. 8190 0.60 granite-8b-japanese New IBM Supports Q&A, summarization, classification, generation, extraction, translation and RAG tasks in Japanese. 4096 0.60 llama-3-8b-instruct New Meta Supports summarization, classification, generation, extraction and translation tasks. 8192 0.60 llama-3-70b-instruct New Meta Supports RAG, generation, summarization, classification, Q&A, extraction, translation and code generation tasks. 8192 1.80 llama-2-70b-chat Meta Supports Q&A, summarization, classification, generation, extraction and RAG tasks. 4096 1.80 llama-2-13b-chat Meta Supports Q&A, summarization, classification, generation, extraction and RAG tasks. Available for prompt tuning. 4096 0.60 llama2-13b-dpo-v7 (Korean) New MindsAndCompany Supports Q&A, summarization, classification, generation, extraction and RAG tasks in Korean. 4096 1.80 codellama-34b-instruct New Meta Task-specific model for code by generating and translating code from a natural language prompt. 16384 1.80 mixtral-8x7b-instruct New Mistral AI Supports Q&A, summarization, classification, generation, extraction, RAG and code generation tasks. 32768 0.60 merlinite-7b New ibm-mistralai Supports Q&A, summarization, classification, generation, extraction, RAG and code generation tasks. 32768 0.60 jais-13b-chat (Arabic) New core42 Supports Q&A, summarization, classification, generation, extraction and translation in Arabic. 2048 1.80 flan-t5-xl-3b Google Supports Q&A, summarization, classification, generation, extraction and RAG tasks. Available for prompt-tuning. 4096 0.60 flan-t5-xxl-11b Google Supports Q&A, summarization, classification, generation, extraction and RAG tasks. 4096 1.80 flan-ul2-20b Google Supports Q&A, summarization, classification, generation, extraction and RAG tasks. 4096 5.00 elyza-japanese-llama-2-7b-instruct ELYZA Supports Q&A, summarization, RAG, classification, generation, extraction and translation tasks. 4096 1.80 mt0-xxl-13b BigScience Supports Q&A, summarization, classification and generation tasks. 4096 1.80 starcoder-15.5b BigCode Task-specific model for code by generating and translating code from a natural language prompt. 8192 1.80 Embedding model library Embedding models convert input text into embeddings, which are dense vector representations of the input text. Embeddings capture nuanced semantic and syntactic relationships between words and passages in vector space. Model name Provider Use cases Context length Price USD/1 million tokens slate-125m-english-rtrvr New IBM Retrieval augmented generation, semantic search and document comparison tasks. 512 0.10 slate-30m-english-rtrvr New IBM Retrieval augmented generation, semantic search and document comparison tasks. 512 0.10 Client stories Businesses are excited about the prospect of tapping foundation models and ML in one place, with their own data, to accelerate generative AI workloads. Explore more client stories Wimbledon Wimbledon used watsonx.ai foundation models to train its AI to create tennis commentary. Read the case study The Recording Academy® The Recording Academy® used AI Stories with IBM watsonx to generate and scale editorial content around GRAMMY® nominees. Read the announcement The Masters Watsonx brings AI-powered hole insights and Spanish language AI narration to the Masters Tournament digital platforms. Read the announcement AddAI.Life AddAI.Life uses watsonx.ai to access selected open-source large language models to build higher quality virtual assistants. Read the case study News and resources News Open-source Mixtral 8x7b model now available on watsonx to help enterprises scale AI with trust and flexibility Read the announcement Ebook How to choose the right AI foundation model Read the ebook Ebook Generative AI and ML for the enterprise Read the ebook News IBM and Meta Llama 2 launches in watsonx.ai, improving AI productivity Read the announcement Blog Hugging Face and IBM working together in open source Read the blog Blog Building AI for business: IBM Granite foundation models Read the blog Blog Introducing the technology behind watsonx.ai Read the blog White paper Presto: Make sense of all your data Read the white paper Blog How IBM is tailoring generative AI for enterprises Read the blog Blog Learn more about the power of AI tailored to your unique needs Read the blog Video See how to build enterprise-ready foundation models Watch the video Intellectual property protection for AI models IBM believes in the creation, deployment and utilization of AI models that advance innovation across the enterprise responsibly. IBM watsonx AI and data platform has an end-to-end process for building and testing foundation models and generative AI. For IBM-developed models, we search for and remove duplication, and we employ URL blocklists, filters for objectionable content and document quality, sentence splitting and tokenization techniques, all before model training. During the data training process, we work to prevent misalignments in the model outputs and use supervised fine-tuning to enable better instruction following so that the model can be used to complete enterprise tasks via prompt engineering. We are continuing to develop the Granite models in several directions, including other modalities, industry-specific content and more data annotations for training, while also deploying regular, ongoing data protection safeguards for IBM developed-models. Given the rapidly changing generative AI technology landscape, our end-to-end processes is expected to continuously evolve and improve. As a testament to the rigor IBM puts into the development and testing of its foundation models, the company provides its standard contractual intellectual property indemnification for IBM-developed models, similar to those it provides for IBM hardware and software products. Moreover, contrary to some other providers of large language models and consistent with the IBM standard approach on indemnification, IBM does not require its customers to indemnify IBM for a customer's use of IBM-developed models. Also, consistent with the IBM approach to its indemnification obligation, IBM does not cap its indemnification liability for the IBM-developed models. The current watsonx models now under these protections include: (1) Slate family of encoder-only models. (2) Granite family of a decoder-only model. Learn more about licensing for Granite models Take the next step Take the next step to start operationalizing and scaling generative AI and machine learning for business. Start your free trial Book a live demo More ways to explore Become an IBM Business Partner Connect with the IBM Community SaaS documentation Software documentation Support Footnotes Inference is billed in Resource Units. 1 Resource Unit is 1,000 tokens. Input and completion tokens are charged at the same rate. 1,000 tokens are generally about 750 words. Not all models are available in all regions, see our documentation for details. Context length is expressed in tokens. The IBM statements regarding its plans, directions and intent are subject to change or withdrawal without notice at its sole discretion. See Pricing for more details. Unless otherwise specified under Software pricing, all features, capabilities and potential updates refer exclusively to SaaS. IBM makes no representation that SaaS and software features and capabilities are the same.\", metadata={'source': './corpus/products_watsonx_ai_foundation_models.html', 'title': 'Foundation Models - IBM watsonx.ai', 'id': 0, 'fileName': 'https://www.ibm.com/products/watsonx-ai/foundation-models'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split up our text into smaller, more manageable pieces known as \"chunks\". LangChain's `RecursiveCharacterTextSplitter` takes a large text and splits it based on a specified chunk size using a predefined set of characters. The default characters are [\"\\n\\n\", \"\\n\", \" \", \"\"].\n",
    "\n",
    "The process starts by attempting to split the text using the first character, \\n\\n. If the resulting chunks are still too large, it moves to the next character, \\n, and tries splitting again. This continues with each character in the set until the chunks are smaller than the specified chunk size.\n",
    "\n",
    "We settled on a chunk size of 512 after experimenting with a chunk size of 1000. When the chunks were that large, our model was getting too much context for question-answering, so we changed it to smaller chunks. Feel free to experiment with chunk size further!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we choose an embedding model to be trained on our Think 2024 dataset. The trained embedding model is used to generate embeddings for each data point in the dataset. For text data, popular open-source embedding models include Word2Vec, GloVe, FastText or pre-trained transformer-based models like BERT or RoBERTa. OpenAIembeddings may also be used by leveraging the OpenAI embeddings API endpoint and getting an `openai_api_key`, however, there is a cost associated with this usage.\n",
    "\n",
    "Unfortunately, because the embedding models are so large, vector embedding often demands significant computational resources like a GPU. We can greatly lower the costs linked to embedding vectors, while preserving performance and accuracy by using Huggingface embeddings.\n",
    "\n",
    "Huggingface is an NLP library that provides a vast array of pre-trained models and embeddings. These embeddings, generated from models like BERT, GPT and RoBERTa, encapsulate semantic information from text. Unlike traditional embedding methods that necessitate training from scratch, Huggingface embeddings offer precomputed representations that can be immediately used for various NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Users/erikarussi/.pyenv/versions/3.10.13/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our content into a local instance of a vector database, using Chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectordb = Chroma(persist_directory='saved_vdb', embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a quick search of our vector database to test it out! Using `similarity_search_with_score` allows us to return the documents and the distance score of the query to them. The returned distance score is Euclidean distance. Therefore, a lower score is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='addressing issues and solving problems before they happen. Concert will initially focus on helping application owners, SREs and IT leaders gain insights about, pre-empt and more quickly address issues around application risk and compliance management. Read this blog to learn more about IBM Concert. IBM expands ecosystem access to watsonx, adds third-party models IBM continues to foster a strong ecosystem of partners to offer clients choice and flexibility through bringing third-party models onto watsonx,', metadata={'fileName': 'https://newsroom.ibm.com/2024-05-21-IBM-Unveils-Next-Chapter-of-watsonx-with-Open-Source,-Product-Ecosystem-Innovations-to-Drive-Enterprise-AI-at-Scale', 'id': 8, 'source': './corpus/watsonx_open_source.html', 'title': 'IBM Unveils Next Chapter of watsonx with Open Source, Product & Ecosystem Innovations to Drive Enterprise AI at Scale'}),\n",
       "  0.6187030076980591),\n",
       " (Document(page_content='application risk and compliance management. Read this blog to learn more about IBM Concert. IBM expands ecosystem access to watsonx, adds third-party models IBM continues to foster a strong ecosystem of partners to offer clients choice and flexibility through bringing third-party models onto watsonx, enabling leading software companies to embed watsonx capabilities into their technologies, and offering IBM Consulting expertise for enterprise business transformation. IBM Consulting has rapidly expanded its', metadata={'fileName': 'IBM Concert', 'id': 26, 'source': './corpus/ibm_concert.txt', 'title': 'IBM Concert'}),\n",
       "  0.761165201663971),\n",
       " (Document(page_content='Think 2024 FAQ | IBM FAQ Register now View session catalog Event information Think 2024 will be held in Boston, MA. It will open with an exclusive, partner-only event on 20 May, filled with inspiration, networking, knowledge-sharing and business value for IBM’s global ecosystem of partners. Then, on 21–23 May, we will bring together senior business and technology leaders from across industries for two and a half days of exploration, discussion and innovation. Think 2024 will host senior business and', metadata={'fileName': 'https://www.ibm.com/events/think/faq', 'id': 3, 'source': './corpus/ibm.com_events_think_faq.html', 'title': 'Think 2024 FAQ | IBM'}),\n",
       "  0.7849763631820679),\n",
       " (Document(page_content='solutions in all areas of their businesses. Ready for the Automation platform of tomorrow IBM today is also previewing IBM Concert®, a new tool powered by the IBM watsonx AI and data platform that will provide visibility and insight into the entire ecosystem of business applications, and the clouds, networks, and assets on which they are built. IBM consultants can help clients establish an integrated AIOps strategy including risk, compliance and certificate management, and apply IBM Concert and other', metadata={'fileName': 'https://newsroom.ibm.com/Blog-IBM-Consulting-Expands-Capabilities-to-Help-Enterprises-Scale-AI', 'id': 21, 'source': './corpus/ibm_consulting_expands_ai.html', 'title': 'IBM Consulting Expands Capabilities to Help Enterprises Scale AI'}),\n",
       "  0.80158531665802)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"What is IBM concert?\"\n",
    "search = vectorstore.similarity_search_with_score(prompt)\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='up now to attend Think 2024, 20–23 May in Boston Register now When we know, you’ll know Get updates on speakers, sessions and essential conference information, delivered right to your inbox. Subscribe', metadata={'fileName': 'https://www.ibm.com/events/think/agenda', 'id': 13, 'source': './corpus/events_think_agenda.html', 'title': 'IBM Think 2024 Agenda'}),\n",
       "  0.5850661396980286),\n",
       " (Document(page_content='technology leaders from across industries. Content will be geared toward C-level, line of business and senior IT leaders. Think 2024 programming will be held at the Boston Convention & Exhibition Center (BCEC), with some activities at the Omni Boston Hotel at the Seaport. At IBM, we are committed to sustainability and environmentally responsible event planning. We are proud to partner with two distinguished venues, each known for their exemplary sustainable practices. Our event will take place at the', metadata={'fileName': 'https://www.ibm.com/events/think/faq', 'id': 3, 'source': './corpus/ibm.com_events_think_faq.html', 'title': 'Think 2024 FAQ | IBM'}),\n",
       "  0.5929423570632935),\n",
       " (Document(page_content='industries. Content will be geared toward C-level, line of business and senior IT leaders. Think 2024 programming will be held at the Boston Convention & Exhibition Center (BCEC), with some activities at the Omni Boston Hotel at the Seaport. At IBM, we are committed to sustainability and environmentally responsible event planning. We are proud to partner with two distinguished venues, each known for their exemplary sustainable practices. Our event will take place at the Boston Convention & Exhibition', metadata={'fileName': 'IBM Concert', 'id': 26, 'source': './corpus/ibm_concert.txt', 'title': 'IBM Concert'}),\n",
       "  0.6141491532325745),\n",
       " (Document(page_content='Register now View session catalog Event information Think 2024 will be held in Boston, MA. It will open with an exclusive, partner-only event on 20 May, filled with inspiration, networking, knowledge-sharing and business value for IBM’s global ecosystem of partners. Then, on 21–23 May, we will bring together senior business and technology leaders from across industries for two and a half days of exploration, discussion and innovation. Think 2024 will host senior business and technology leaders from across', metadata={'fileName': 'IBM Concert', 'id': 26, 'source': './corpus/ibm_concert.txt', 'title': 'IBM Concert'}),\n",
       "  0.6350926160812378)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Where is Think 2024?\"\n",
    "search = vectorstore.similarity_search_with_score(prompt)\n",
    "search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Set up a retriever\n",
    "\n",
    "We'll set up our vector store as a retriever. The retrieved information from the vector store serves as additional context or knowledge that can be used by a generative model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Generate a response with a Generative Model\n",
    "\n",
    "Finally, we’ll generate a response. The generative model (like GPT-4 or IBM Granite) uses the retrieved information to produce a more accurate and contextually relevant response to our questions about Think 2024.\n",
    "\n",
    "First, we'll establish which LLM we're going to use to generate the response. For this tutorial, we'll use IBM's Granite 13B Chat model. Don't forget to load in your API credentials to access this model using the [IBM GenAI SDK](https://github.com/IBM/ibm-generative-ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM_GRANITE_13B_CHAT_V2 = \"ibm/granite-13b-chat-v2\"\n",
    "# MODEL_ID_PARAMS = {\n",
    "#     IBM_GRANITE_13B_CHAT_V2: TextGenerationParameters(\n",
    "#         decoding_method=\"greedy\",\n",
    "#         max_new_tokens=512,\n",
    "#         min_new_tokens=10,\n",
    "#         repetition_penalty=1.2,\n",
    "#         return_options=TextGenerationReturnOptions(\n",
    "#     generated_tokens=True,\n",
    "#     token_logprobs=True,\n",
    "#     token_ranks=True,\n",
    "#     # input_tokens=True\n",
    "#     # top_n_tokens=\n",
    "# ))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LangChainChatInterface(\n",
    "    client=Client(credentials=Credentials.from_env()),\n",
    "    model_id= \"ibm/granite-13b-chat-v2\",\n",
    "    parameters=TextGenerationParameters(\n",
    "        decoding_method=\"greedy\",\n",
    "        max_new_tokens=512,\n",
    "        min_new_tokens=10,\n",
    "        repetition_penalty=1.2,\n",
    "        return_options=TextGenerationReturnOptions(\n",
    "            generated_tokens=True,\n",
    "            token_logprobs=True,\n",
    "            token_ranks=True,)\n",
    "            )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll set up a `prompttemplate` to ask multiple questions. The \"context\" will be derived from our retriever (our vector database) with the relevant documents and the \"question\" will be derived from the user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up a helper function to format the docs accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can set up a chain with our context, our prompt and out LLM. The generative model processes the augmented context along with the user's question to produce a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can ask multiple questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Think 2024 is being held in Boston, Massachusetts. The specific venue mentioned is the Boston Convention & Exhibition Center (BCEC).'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Where is Think 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBM Concert is described as \"a new tool powered by the IBM watsonx AI and data platform that will provide visibility and insight into the entire ecosystem of business applications, and the clouds, networks, and assets on which they are built.\"'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is IBM Concert?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IBM Think 2024 is a conference or event where IBM announces new products, technologies, and partnerships related to artificial intelligence and other areas of interest to businesses and organizations. The most recent edition of this event was held in Boston, Massachusetts, and featured sessions and discussions aimed at senior business and technology leaders.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is IBM Think 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it! Feel free to ask even more questions!\n",
    "\n",
    "You can imagine a situation where we can create chatbots to field these questions.\n",
    "\n",
    "We encourage you to check out the [LangChain documentation page](https://python.langchain.com/v0.2/docs/tutorials/rag/) for more information and tutorials on RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
